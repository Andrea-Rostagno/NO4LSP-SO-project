\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\citation{nocedal1999}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Modified Newton Method}{2}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Nelder--Mead Method}{3}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Finite Differences}{4}{subsection.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Rosenbrock Function in Dimension 2}{5}{section.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Surface plot of the Rosenbrock function over the domain $[-2, 2] \times [-1, 3]$. The function exhibits a narrow curved valley with a global minimum at $(1, 1)$, where $f(x) = 0$. This geometry makes it a standard benchmark for testing unconstrained optimization algorithms.}}{5}{figure.1}\protected@file@percent }
\newlabel{fig:rosennewton}{{1}{5}{Surface plot of the Rosenbrock function over the domain $[-2, 2] \times [-1, 3]$. The function exhibits a narrow curved valley with a global minimum at $(1, 1)$, where $f(x) = 0$. This geometry makes it a standard benchmark for testing unconstrained optimization algorithms}{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Convergence behaviour of the Modified Newton method on the Rosenbrock function starting from $x^{(0)} = [1.2, 1.2]$ and $x^{(0)} = [-1.2, 1.0]$.}}{6}{figure.2}\protected@file@percent }
\newlabel{fig:rosennewton}{{2}{6}{Convergence behaviour of the Modified Newton method on the Rosenbrock function starting from $x^{(0)} = [1.2, 1.2]$ and $x^{(0)} = [-1.2, 1.0]$}{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Convergence behaviour of the Nelder Mead method on the Rosenbrock function starting from $x^{(0)} = [1.2, 1.2]$ and $x^{(0)} = [-1.2, 1.0]$.}}{7}{figure.3}\protected@file@percent }
\newlabel{fig:rosennewton}{{3}{7}{Convergence behaviour of the Nelder Mead method on the Rosenbrock function starting from $x^{(0)} = [1.2, 1.2]$ and $x^{(0)} = [-1.2, 1.0]$}{figure.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Extended Rosenbrock Function}{8}{section.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces 3D visualization of the Extended Rosenbrock function in dimension $n=2$. The global minimum lies at $(1,1)$, and the function exhibits a curved valley that becomes increasingly difficult to navigate in higher dimensions.}}{8}{figure.4}\protected@file@percent }
\newlabel{fig:extrosen3d}{{4}{8}{3D visualization of the Extended Rosenbrock function in dimension $n=2$. The global minimum lies at $(1,1)$, and the function exhibits a curved valley that becomes increasingly difficult to navigate in higher dimensions}{figure.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Modified Newton with Exact Gradient and Hessian}{9}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Gradient and Hessian structure.}{9}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Motivation for sparse representation.}{9}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Experimental setup.}{10}{section*.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Convergence of the Modified Newton method with exact derivatives on the Extended Rosenbrock function for $n=1000$. Each curve corresponds to a different initial point. The method converges quadratically with stable behaviour across all tests.}}{11}{figure.5}\protected@file@percent }
\newlabel{fig:extnewton_1k}{{5}{11}{Convergence of the Modified Newton method with exact derivatives on the Extended Rosenbrock function for $n=1000$. Each curve corresponds to a different initial point. The method converges quadratically with stable behaviour across all tests}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Convergence of the Modified Newton method on the Extended Rosenbrock function for $n=10\,000$. The method exhibits consistent quadratic convergence also in higher dimension.}}{11}{figure.6}\protected@file@percent }
\newlabel{fig:extnewton_10k}{{6}{11}{Convergence of the Modified Newton method on the Extended Rosenbrock function for $n=10\,000$. The method exhibits consistent quadratic convergence also in higher dimension}{figure.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Convergence of the Modified Newton method on the Extended Rosenbrock function for $n=100\,000$. Despite the high dimensionality, the convergence remains stable with similar iteration counts.}}{12}{figure.7}\protected@file@percent }
\newlabel{fig:extnewton_100k}{{7}{12}{Convergence of the Modified Newton method on the Extended Rosenbrock function for $n=100\,000$. Despite the high dimensionality, the convergence remains stable with similar iteration counts}{figure.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Execution time (in seconds) of the Modified Newton method with exact derivatives for $n=10^3$, $10^4$ and $10^5$. The runtime grows approximately linearly with the problem size, confirming the efficiency of sparse matrix operations.}}{12}{figure.8}\protected@file@percent }
\newlabel{fig:extnewton_times}{{8}{12}{Execution time (in seconds) of the Modified Newton method with exact derivatives for $n=10^3$, $10^4$ and $10^5$. The runtime grows approximately linearly with the problem size, confirming the efficiency of sparse matrix operations}{figure.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Finite Differences Gradient and Hessian}{13}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Gradient approximation.}{13}{section*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Hessian approximation.}{13}{section*.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Experimental results.}{14}{section*.8}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Finite difference results for $n=1\,000$ using different increments $h$ and strategies.}}{15}{table.1}\protected@file@percent }
\newlabel{tab:fd_ext_1000}{{1}{15}{Finite difference results for $n=1\,000$ using different increments $h$ and strategies}{table.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Convergence of Modified Newton method on Extended Rosenbrock function ($n=1000$) with fixed increment $h = 10^{-2}$ (left) and scaled increment $h = 10^{-2}\cdot |x|$ (right).}}{16}{figure.9}\protected@file@percent }
\newlabel{fig:fd_1k_h2}{{9}{16}{Convergence of Modified Newton method on Extended Rosenbrock function ($n=1000$) with fixed increment $h = 10^{-2}$ (left) and scaled increment $h = 10^{-2}\cdot |x|$ (right)}{figure.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Convergence of Modified Newton method on Extended Rosenbrock function ($n=1000$) with fixed increment $h = 10^{-12}$ (left) and scaled increment $h = 10^{-12}\cdot |x|$ (right).}}{16}{figure.10}\protected@file@percent }
\newlabel{fig:fd_1k_h12}{{10}{16}{Convergence of Modified Newton method on Extended Rosenbrock function ($n=1000$) with fixed increment $h = 10^{-12}$ (left) and scaled increment $h = 10^{-12}\cdot |x|$ (right)}{figure.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Finite difference results for $n=10\,000$ using different increments $h$ and strategies.}}{18}{table.2}\protected@file@percent }
\newlabel{tab:fd_er_10000}{{2}{18}{Finite difference results for $n=10\,000$ using different increments $h$ and strategies}{table.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Convergence of Modified Newton method on Extended Rosenbrock function ($n=10\,000$) with fixed increment $h = 10^{-2}$ (left) and scaled increment $h = 10^{-2}\cdot |x|$ (right).}}{19}{figure.11}\protected@file@percent }
\newlabel{fig:fd_10k_h2}{{11}{19}{Convergence of Modified Newton method on Extended Rosenbrock function ($n=10\,000$) with fixed increment $h = 10^{-2}$ (left) and scaled increment $h = 10^{-2}\cdot |x|$ (right)}{figure.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Convergence of Modified Newton method on Extended Rosenbrock function ($n=10\,000$) with fixed increment $h = 10^{-12}$ (left) and scaled increment $h = 10^{-12}\cdot |x|$ (right).}}{19}{figure.12}\protected@file@percent }
\newlabel{fig:fd_10k_h12}{{12}{19}{Convergence of Modified Newton method on Extended Rosenbrock function ($n=10\,000$) with fixed increment $h = 10^{-12}$ (left) and scaled increment $h = 10^{-12}\cdot |x|$ (right)}{figure.12}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Finite difference results for $n=100\,000$ using different increments $h$ and strategies.}}{21}{table.3}\protected@file@percent }
\newlabel{tab:fd_rosenbrock_100000}{{3}{21}{Finite difference results for $n=100\,000$ using different increments $h$ and strategies}{table.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Convergence of Modified Newton method on Extended Rosenbrock function ($n=100\,000$) with fixed increment $h = 10^{-2}$ (left) and scaled increment $h = 10^{-2}\cdot |x|$ (right).}}{22}{figure.13}\protected@file@percent }
\newlabel{fig:fd_100k_h2}{{13}{22}{Convergence of Modified Newton method on Extended Rosenbrock function ($n=100\,000$) with fixed increment $h = 10^{-2}$ (left) and scaled increment $h = 10^{-2}\cdot |x|$ (right)}{figure.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Convergence of Modified Newton method on Extended Rosenbrock function ($n=100\,000$) with fixed increment $h = 10^{-12}$ (left) and scaled increment $h = 10^{-12}\cdot |x|$ (right).}}{22}{figure.14}\protected@file@percent }
\newlabel{fig:fd_100k_h12}{{14}{22}{Convergence of Modified Newton method on Extended Rosenbrock function ($n=100\,000$) with fixed increment $h = 10^{-12}$ (left) and scaled increment $h = 10^{-12}\cdot |x|$ (right)}{figure.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Nelder–Mead Method on Extended Rosenbrock Function}{23}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Experimental setup.}{23}{section*.12}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Results.}{24}{section*.13}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Results of Nelder–Mead on Extended Rosenbrock function.}}{24}{table.4}\protected@file@percent }
\newlabel{tab:nelder_rosenbrock}{{4}{24}{Results of Nelder–Mead on Extended Rosenbrock function}{table.4}{}}
\@writefile{toc}{\contentsline {paragraph}{Discussion.}{24}{section*.14}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Convergence of Nelder–Mead on Extended Rosenbrock function ($n=10$) from reference and 10 random initial points. The objective decreases but stagnates above the global minimum.}}{25}{figure.15}\protected@file@percent }
\newlabel{fig:nelder_rosen_10}{{15}{25}{Convergence of Nelder–Mead on Extended Rosenbrock function ($n=10$) from reference and 10 random initial points. The objective decreases but stagnates above the global minimum}{figure.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Convergence of Nelder–Mead on Extended Rosenbrock function ($n=26$). Progress slows down and most trajectories fail to improve after early iterations.}}{25}{figure.16}\protected@file@percent }
\newlabel{fig:nelder_rosen_26}{{16}{25}{Convergence of Nelder–Mead on Extended Rosenbrock function ($n=26$). Progress slows down and most trajectories fail to improve after early iterations}{figure.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Convergence of Nelder–Mead on Extended Rosenbrock function ($n=50$). None of the trials reach satisfactory objective values, confirming the method’s limits in high dimensions.}}{26}{figure.17}\protected@file@percent }
\newlabel{fig:nelder_rosen_50}{{17}{26}{Convergence of Nelder–Mead on Extended Rosenbrock function ($n=50$). None of the trials reach satisfactory objective values, confirming the method’s limits in high dimensions}{figure.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Execution time of Nelder–Mead on Extended Rosenbrock for increasing dimensions $n=10$, $26$, and $50$. The cost grows sharply due to the increased simplex size.}}{26}{figure.18}\protected@file@percent }
\newlabel{fig:nelder_rosen_times}{{18}{26}{Execution time of Nelder–Mead on Extended Rosenbrock for increasing dimensions $n=10$, $26$, and $50$. The cost grows sharply due to the increased simplex size}{figure.18}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Generalized Broyden Tridiagonal Function}{27}{section.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces 3D visualization of the Generalized Broyden Tridiagonal function for $n=2$.}}{27}{figure.19}\protected@file@percent }
\newlabel{fig:broyden3D}{{19}{27}{3D visualization of the Generalized Broyden Tridiagonal function for $n=2$}{figure.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Modified Newton Exact Gradient and Hessian}{28}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Gradient structure.}{28}{section*.15}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Hessian structure.}{28}{section*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Results.}{29}{section*.17}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Results of Modified Newton method on Generalized Broyden function using exact derivatives.}}{29}{table.5}\protected@file@percent }
\newlabel{tab:gb_exact_all}{{5}{29}{Results of Modified Newton method on Generalized Broyden function using exact derivatives}{table.5}{}}
\@writefile{toc}{\contentsline {paragraph}{Discussion.}{29}{section*.18}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Convergence of the Modified Newton method on Generalized Broyden function with $n=1000$ using exact gradient and Hessian. The method converges in few iterations with a consistent superlinear rate.}}{30}{figure.20}\protected@file@percent }
\newlabel{fig:gb_1k_exact}{{20}{30}{Convergence of the Modified Newton method on Generalized Broyden function with $n=1000$ using exact gradient and Hessian. The method converges in few iterations with a consistent superlinear rate}{figure.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Convergence of the Modified Newton method on Generalized Broyden function with $n=10000$. The convergence behavior remains stable across all random initializations.}}{31}{figure.21}\protected@file@percent }
\newlabel{fig:gb_10k_exact}{{21}{31}{Convergence of the Modified Newton method on Generalized Broyden function with $n=10000$. The convergence behavior remains stable across all random initializations}{figure.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Convergence of the Modified Newton method on Generalized Broyden function with $n=100000$. Even in high dimensions, the algorithm remains robust and fast.}}{31}{figure.22}\protected@file@percent }
\newlabel{fig:gb_100k_exact}{{22}{31}{Convergence of the Modified Newton method on Generalized Broyden function with $n=100000$. Even in high dimensions, the algorithm remains robust and fast}{figure.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Execution time of the Modified Newton method with exact derivatives on Generalized Broyden function for increasing dimensions. The computation scales efficiently due to sparse Hessian structure.}}{32}{figure.23}\protected@file@percent }
\newlabel{fig:gb_time_exact}{{23}{32}{Execution time of the Modified Newton method with exact derivatives on Generalized Broyden function for increasing dimensions. The computation scales efficiently due to sparse Hessian structure}{figure.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Newton Method Finite Differences Gradient and Hessian}{32}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Finite difference formulas.}{32}{section*.19}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Results.}{33}{section*.20}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Finite difference results for $n=1000$ using different increments $h$ and strategies.}}{34}{table.6}\protected@file@percent }
\newlabel{tab:gb_fd_1000_all}{{6}{34}{Finite difference results for $n=1000$ using different increments $h$ and strategies}{table.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Convergence of Modified Newton method on Generalized Broyden function ($n=1000$) with fixed increment $h = 10^{-2}$ (left) and scaled increment $h = 10^{-2}\cdot |x|$ (right).}}{35}{figure.24}\protected@file@percent }
\newlabel{fig:fd_broyden_1k_h2}{{24}{35}{Convergence of Modified Newton method on Generalized Broyden function ($n=1000$) with fixed increment $h = 10^{-2}$ (left) and scaled increment $h = 10^{-2}\cdot |x|$ (right)}{figure.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Convergence of Modified Newton method on Generalized Broyden function ($n=1000$) with fixed increment $h = 10^{-12}$ (left) and scaled increment $h = 10^{-12}\cdot |x|$ (right).}}{35}{figure.25}\protected@file@percent }
\newlabel{fig:fd_broyden_1k_h12}{{25}{35}{Convergence of Modified Newton method on Generalized Broyden function ($n=1000$) with fixed increment $h = 10^{-12}$ (left) and scaled increment $h = 10^{-12}\cdot |x|$ (right)}{figure.25}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Finite difference results for $n=10\,000$ using different increments $h$ and strategies.}}{36}{table.7}\protected@file@percent }
\newlabel{tab:gb_fd_10000}{{7}{36}{Finite difference results for $n=10\,000$ using different increments $h$ and strategies}{table.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Convergence of Modified Newton method on Generalized Broyden function ($n=10000$) with fixed increment $h = 10^{-2}$ (left) and scaled increment $h = 10^{-2}\cdot |x|$ (right).}}{37}{figure.26}\protected@file@percent }
\newlabel{fig:fd_broyden_10k_h2}{{26}{37}{Convergence of Modified Newton method on Generalized Broyden function ($n=10000$) with fixed increment $h = 10^{-2}$ (left) and scaled increment $h = 10^{-2}\cdot |x|$ (right)}{figure.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces Convergence of Modified Newton method on Generalized Broyden function ($n=10000$) with fixed increment $h = 10^{-12}$ (left) and scaled increment $h = 10^{-12}\cdot |x|$ (right).}}{37}{figure.27}\protected@file@percent }
\newlabel{fig:fd_broyden_10k_h12}{{27}{37}{Convergence of Modified Newton method on Generalized Broyden function ($n=10000$) with fixed increment $h = 10^{-12}$ (left) and scaled increment $h = 10^{-12}\cdot |x|$ (right)}{figure.27}{}}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Finite difference results for $n=100\,000$ using different increments $h$ and strategies.}}{38}{table.8}\protected@file@percent }
\newlabel{tab:gb_fd_100000}{{8}{38}{Finite difference results for $n=100\,000$ using different increments $h$ and strategies}{table.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces Convergence of Modified Newton method on Generalized Broyden function ($n=100000$) with fixed increment $h = 10^{-2}$ (left) and scaled increment $h = 10^{-2}\cdot |x|$ (right).}}{39}{figure.28}\protected@file@percent }
\newlabel{fig:fd_broyden_100k_h2}{{28}{39}{Convergence of Modified Newton method on Generalized Broyden function ($n=100000$) with fixed increment $h = 10^{-2}$ (left) and scaled increment $h = 10^{-2}\cdot |x|$ (right)}{figure.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces Convergence of Modified Newton method on Generalized Broyden function ($n=100000$) with fixed increment $h = 10^{-12}$ (left) and scaled increment $h = 10^{-12}\cdot |x|$ (right).}}{39}{figure.29}\protected@file@percent }
\newlabel{fig:fd_broyden_100k_h12}{{29}{39}{Convergence of Modified Newton method on Generalized Broyden function ($n=100000$) with fixed increment $h = 10^{-12}$ (left) and scaled increment $h = 10^{-12}\cdot |x|$ (right)}{figure.29}{}}
\@writefile{toc}{\contentsline {paragraph}{Discussion.}{40}{section*.21}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Nelder–Mead Results on Generalized Broyden Function}{41}{subsection.4.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces Results of Nelder–Mead on Generalized Broyden Tridiagonal function.}}{41}{table.9}\protected@file@percent }
\newlabel{tab:neldermead_generalized_broyden}{{9}{41}{Results of Nelder–Mead on Generalized Broyden Tridiagonal function}{table.9}{}}
\@writefile{toc}{\contentsline {paragraph}{Discussion.}{41}{section*.22}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {30}{\ignorespaces Convergence of Nelder-Mead method on Generalized Broyden function ($n=10$) for the reference point $\bar  {x}$ (black) and $10$ randomly generated starting points.}}{42}{figure.30}\protected@file@percent }
\newlabel{fig:gb_nelder_10}{{30}{42}{Convergence of Nelder-Mead method on Generalized Broyden function ($n=10$) for the reference point $\bar {x}$ (black) and $10$ randomly generated starting points}{figure.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {31}{\ignorespaces Convergence of Nelder-Mead method on Generalized Broyden function ($n=26$) for the reference point $\bar  {x}$ (black) and $10$ randomly generated starting points.}}{42}{figure.31}\protected@file@percent }
\newlabel{fig:gb_nelder_26}{{31}{42}{Convergence of Nelder-Mead method on Generalized Broyden function ($n=26$) for the reference point $\bar {x}$ (black) and $10$ randomly generated starting points}{figure.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {32}{\ignorespaces Convergence of Nelder-Mead method on Generalized Broyden function ($n=50$) for the reference point $\bar  {x}$ (black) and $10$ randomly generated starting points.}}{43}{figure.32}\protected@file@percent }
\newlabel{fig:gb_nelder_50}{{32}{43}{Convergence of Nelder-Mead method on Generalized Broyden function ($n=50$) for the reference point $\bar {x}$ (black) and $10$ randomly generated starting points}{figure.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {33}{\ignorespaces Computational time (in seconds) for Nelder-Mead method applied to the Generalized Broyden function for increasing dimensions.}}{43}{figure.33}\protected@file@percent }
\newlabel{fig:gb_nelder_time}{{33}{43}{Computational time (in seconds) for Nelder-Mead method applied to the Generalized Broyden function for increasing dimensions}{figure.33}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Banded Trigonometric Function}{44}{section.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {34}{\ignorespaces 3D visualization of the Banded Trigonometric function for $n=2$.}}{44}{figure.34}\protected@file@percent }
\newlabel{fig:broyden3D}{{34}{44}{3D visualization of the Banded Trigonometric function for $n=2$}{figure.34}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Exact Gradient and Hessian}{45}{subsection.5.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces Results of Modified Newton method on Banded Trigonometric function using exact derivatives.}}{46}{table.10}\protected@file@percent }
\newlabel{tab:banded_exact}{{10}{46}{Results of Modified Newton method on Banded Trigonometric function using exact derivatives}{table.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {35}{\ignorespaces Convergence of the Modified Newton method on the Banded Trigonometric function ($n=1000$) using exact derivatives.}}{46}{figure.35}\protected@file@percent }
\newlabel{fig:bt_1k_exact}{{35}{46}{Convergence of the Modified Newton method on the Banded Trigonometric function ($n=1000$) using exact derivatives}{figure.35}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {36}{\ignorespaces Convergence of the Modified Newton method on the Banded Trigonometric function ($n=10000$) using exact derivatives.}}{47}{figure.36}\protected@file@percent }
\newlabel{fig:bt_10k_exact}{{36}{47}{Convergence of the Modified Newton method on the Banded Trigonometric function ($n=10000$) using exact derivatives}{figure.36}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {37}{\ignorespaces Convergence of the Modified Newton method on the Banded Trigonometric function ($n=100000$) using exact derivatives.}}{47}{figure.37}\protected@file@percent }
\newlabel{fig:bt_100k_exact}{{37}{47}{Convergence of the Modified Newton method on the Banded Trigonometric function ($n=100000$) using exact derivatives}{figure.37}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {38}{\ignorespaces Computational time required by the Modified Newton method on the Banded Trigonometric function with exact derivatives for each problem size.}}{48}{figure.38}\protected@file@percent }
\newlabel{fig:bt_time_exact}{{38}{48}{Computational time required by the Modified Newton method on the Banded Trigonometric function with exact derivatives for each problem size}{figure.38}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Finite Differences Gradient and Hessian}{48}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Results.}}{48}{table.11}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {11}{\ignorespaces Finite difference results for $n=1\,000$ using different increments $h$ and strategies.}}{49}{table.11}\protected@file@percent }
\newlabel{tab:banded_fd_1000}{{11}{49}{Finite difference results for $n=1\,000$ using different increments $h$ and strategies}{table.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {39}{\ignorespaces Convergence of the Modified Newton method on the Banded Trigonometric function ($n=1000$) using fixed increment $h = 10^{-2}$ (left) and scaled increment $h = 10^{-2}\cdot |x|$ (right).}}{50}{figure.39}\protected@file@percent }
\newlabel{fig:bt_fd_1k_h2}{{39}{50}{Convergence of the Modified Newton method on the Banded Trigonometric function ($n=1000$) using fixed increment $h = 10^{-2}$ (left) and scaled increment $h = 10^{-2}\cdot |x|$ (right)}{figure.39}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {40}{\ignorespaces Convergence of the Modified Newton method on the Banded Trigonometric function ($n=1000$) using fixed increment $h = 10^{-12}$ (left) and scaled increment $h = 10^{-12}\cdot |x|$ (right).}}{50}{figure.40}\protected@file@percent }
\newlabel{fig:bt_fd_1k_h12}{{40}{50}{Convergence of the Modified Newton method on the Banded Trigonometric function ($n=1000$) using fixed increment $h = 10^{-12}$ (left) and scaled increment $h = 10^{-12}\cdot |x|$ (right)}{figure.40}{}}
\@writefile{lot}{\contentsline {table}{\numberline {12}{\ignorespaces Finite difference results for $n=10\,000$ using different increments $h$ and strategies.}}{51}{table.12}\protected@file@percent }
\newlabel{tab:bt_fd_10000}{{12}{51}{Finite difference results for $n=10\,000$ using different increments $h$ and strategies}{table.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {41}{\ignorespaces Convergence of the Modified Newton method on the Banded Trigonometric function ($n=10000$) using fixed increment $h = 10^{-2}$ (left) and scaled increment $h = 10^{-2}\cdot |x|$ (right).}}{52}{figure.41}\protected@file@percent }
\newlabel{fig:bt_fd_10k_h2}{{41}{52}{Convergence of the Modified Newton method on the Banded Trigonometric function ($n=10000$) using fixed increment $h = 10^{-2}$ (left) and scaled increment $h = 10^{-2}\cdot |x|$ (right)}{figure.41}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {42}{\ignorespaces Convergence of the Modified Newton method on the Banded Trigonometric function ($n=10000$) using fixed increment $h = 10^{-12}$ (left) and scaled increment $h = 10^{-12}\cdot |x|$ (right).}}{52}{figure.42}\protected@file@percent }
\newlabel{fig:bt_fd_10k_h12}{{42}{52}{Convergence of the Modified Newton method on the Banded Trigonometric function ($n=10000$) using fixed increment $h = 10^{-12}$ (left) and scaled increment $h = 10^{-12}\cdot |x|$ (right)}{figure.42}{}}
\@writefile{lot}{\contentsline {table}{\numberline {13}{\ignorespaces Finite difference results for $n=100\,000$ using different increments $h$ and strategies.}}{53}{table.13}\protected@file@percent }
\newlabel{tab:banded_fd_100000}{{13}{53}{Finite difference results for $n=100\,000$ using different increments $h$ and strategies}{table.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {43}{\ignorespaces Convergence of the Modified Newton method on the Banded Trigonometric function ($n=100000$) using fixed increment $h = 10^{-2}$ (left) and scaled increment $h = 10^{-2}\cdot |x|$ (right).}}{54}{figure.43}\protected@file@percent }
\newlabel{fig:bt_fd_100k_h2}{{43}{54}{Convergence of the Modified Newton method on the Banded Trigonometric function ($n=100000$) using fixed increment $h = 10^{-2}$ (left) and scaled increment $h = 10^{-2}\cdot |x|$ (right)}{figure.43}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {44}{\ignorespaces Convergence of the Modified Newton method on the Banded Trigonometric function ($n=100000$) using fixed increment $h = 10^{-12}$ (left) and scaled increment $h = 10^{-12}\cdot |x|$ (right).}}{54}{figure.44}\protected@file@percent }
\newlabel{fig:bt_fd_100k_h12}{{44}{54}{Convergence of the Modified Newton method on the Banded Trigonometric function ($n=100000$) using fixed increment $h = 10^{-12}$ (left) and scaled increment $h = 10^{-12}\cdot |x|$ (right)}{figure.44}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Nelder-Mead on Banded Trigonometric Function}{55}{subsection.5.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {14}{\ignorespaces Results of Nelder–Mead on Banded Trigonometric function.}}{55}{table.14}\protected@file@percent }
\newlabel{tab:nelder_banded}{{14}{55}{Results of Nelder–Mead on Banded Trigonometric function}{table.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {45}{\ignorespaces Convergence of Nelder-Mead on the Banded Trigonometric function with $n = 10$.}}{56}{figure.45}\protected@file@percent }
\newlabel{fig:bt_nelder_10}{{45}{56}{Convergence of Nelder-Mead on the Banded Trigonometric function with $n = 10$}{figure.45}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {46}{\ignorespaces Convergence of Nelder-Mead on the Banded Trigonometric function with $n = 26$.}}{56}{figure.46}\protected@file@percent }
\newlabel{fig:bt_nelder_26}{{46}{56}{Convergence of Nelder-Mead on the Banded Trigonometric function with $n = 26$}{figure.46}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {47}{\ignorespaces Convergence of Nelder-Mead on the Banded Trigonometric function with $n = 50$.}}{57}{figure.47}\protected@file@percent }
\newlabel{fig:bt_nelder_50}{{47}{57}{Convergence of Nelder-Mead on the Banded Trigonometric function with $n = 50$}{figure.47}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {48}{\ignorespaces Computation time of Nelder-Mead on the Banded Trigonometric function for $n \in \{10, 26, 50\}$.}}{57}{figure.48}\protected@file@percent }
\newlabel{fig:bt_nelder_time}{{48}{57}{Computation time of Nelder-Mead on the Banded Trigonometric function for $n \in \{10, 26, 50\}$}{figure.48}{}}
\@writefile{toc}{\contentsline {paragraph}{Discussion.}{58}{section*.24}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{58}{section.6}\protected@file@percent }
\gdef \@abspage@last{60}
